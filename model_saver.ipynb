{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "561299a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Shorya\\anaconda3\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:From C:\\Users\\Shorya\\anaconda3\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "26/26 [==============================] - 171s 6s/step - loss: 0.0917 - val_loss: 0.0438\n",
      "Epoch 2/10\n",
      "26/26 [==============================] - 140s 5s/step - loss: 0.0349 - val_loss: 0.0020\n",
      "Epoch 3/10\n",
      "26/26 [==============================] - 140s 5s/step - loss: 0.0082 - val_loss: 4.2913e-04\n",
      "Epoch 4/10\n",
      "26/26 [==============================] - 139s 5s/step - loss: 0.0042 - val_loss: 7.0107e-04\n",
      "Epoch 5/10\n",
      "26/26 [==============================] - 138s 5s/step - loss: 0.0034 - val_loss: 8.6735e-04\n",
      "Epoch 6/10\n",
      "26/26 [==============================] - 138s 5s/step - loss: 0.0025 - val_loss: 9.4290e-04\n",
      "Epoch 7/10\n",
      "26/26 [==============================] - 144s 6s/step - loss: 0.0028 - val_loss: 0.0011\n",
      "Epoch 8/10\n",
      "26/26 [==============================] - 139s 5s/step - loss: 0.0036 - val_loss: 0.0012\n",
      "Epoch 9/10\n",
      "26/26 [==============================] - 180s 7s/step - loss: 0.0025 - val_loss: 0.0012\n",
      "Epoch 10/10\n",
      "26/26 [==============================] - 168s 6s/step - loss: 0.0018 - val_loss: 0.0013\n",
      "2/2 [==============================] - 15s 6s/step\n",
      "Mean Squared Error (Confidence, Fluency): [15.12705757 10.18232526]\n",
      "Mean Absolute Error (Confidence, Fluency): [3.52057049 2.7496931 ]\n",
      "R² Score (Confidence, Fluency): [0.98137328 0.98478538]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import BertTokenizer, TFBertModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "# Load data\n",
    "data = pd.read_excel('score_model/Interview Responses Combined.xlsx')\n",
    "data.dropna(inplace=True)\n",
    "\n",
    "# Split into features and targets\n",
    "X = data['Responses'].tolist()\n",
    "y = data[['Confidence', 'Fluency']].values\n",
    "\n",
    "# Scale target values using Min-Max Scaling\n",
    "scaler = MinMaxScaler()\n",
    "y_scaled = scaler.fit_transform(y)\n",
    "\n",
    "# Load BERT tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "bert_model = TFBertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Tokenize and encode responses\n",
    "def encode_text(text_list):\n",
    "    encoding = tokenizer(\n",
    "        text_list,\n",
    "        padding='max_length',  # Force consistent padding\n",
    "        truncation=True,\n",
    "        max_length=128,\n",
    "        return_tensors=\"tf\"\n",
    "    )\n",
    "    return encoding\n",
    "\n",
    "X_encoded = encode_text(X)\n",
    "\n",
    "# Convert tensors to numpy arrays for training compatibility\n",
    "X_input_ids = np.array(X_encoded['input_ids'])\n",
    "X_attention_mask = np.array(X_encoded['attention_mask'])\n",
    "\n",
    "# Split into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_input_ids, y_scaled, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# BERT Embedding Layer\n",
    "input_ids = Input(shape=(128,), dtype=tf.int32, name='input_ids')\n",
    "attention_mask = Input(shape=(128,), dtype=tf.int32, name='attention_mask')\n",
    "\n",
    "# Pass both input_ids and attention_mask to BERT\n",
    "embedding = bert_model(input_ids, attention_mask=attention_mask)[0][:, 0, :]  # CLS token output\n",
    "\n",
    "# Neural Network layers\n",
    "x = Dense(128, activation='relu')(embedding)\n",
    "x = Dropout(0.3)(x)  # Dropout to prevent overfitting\n",
    "x = Dense(64, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "output = Dense(2, activation='sigmoid')(x)  # Sigmoid for output between 0 and 1\n",
    "\n",
    "# Build model with both inputs\n",
    "model = Model(inputs=[input_ids, attention_mask], outputs=output)\n",
    "model.compile(optimizer=Adam(learning_rate=1e-5), loss='huber_loss')\n",
    "\n",
    "# Train model\n",
    "history = model.fit(\n",
    "    {'input_ids': X_train, 'attention_mask': X_attention_mask[:len(X_train)]},\n",
    "    y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=10,\n",
    "    batch_size=8\n",
    ")\n",
    "\n",
    "# Predict on test set\n",
    "y_pred = model.predict({\n",
    "    'input_ids': X_test,\n",
    "    'attention_mask': X_attention_mask[:len(X_test)]\n",
    "})\n",
    "\n",
    "# Inverse transform to original scale\n",
    "y_pred_rescaled = scaler.inverse_transform(y_pred)\n",
    "y_test_rescaled = scaler.inverse_transform(y_test)\n",
    "\n",
    "# Evaluation\n",
    "mse = mean_squared_error(y_test_rescaled, y_pred_rescaled, multioutput='raw_values')\n",
    "mae = mean_absolute_error(y_test_rescaled, y_pred_rescaled, multioutput='raw_values')\n",
    "r2 = r2_score(y_test_rescaled, y_pred_rescaled, multioutput='raw_values')\n",
    "\n",
    "print(f\"Mean Squared Error (Confidence, Fluency): {mse}\")\n",
    "print(f\"Mean Absolute Error (Confidence, Fluency): {mae}\")\n",
    "print(f\"R² Score (Confidence, Fluency): {r2}\")\n",
    "\n",
    "# Prediction function\n",
    "def predict_response(response):\n",
    "    encoded = encode_text([response])\n",
    "    prediction = model.predict({\n",
    "        'input_ids': np.array(encoded['input_ids']),\n",
    "        'attention_mask': np.array(encoded['attention_mask'])\n",
    "    })\n",
    "    prediction_rescaled = scaler.inverse_transform(prediction)[0]\n",
    "    confidence, fluency = prediction_rescaled\n",
    "    return {\"Confidence\": round(confidence, 2), \"Fluency\": round(fluency, 2)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f70a868c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 196ms/step\n",
      "Predicted Scores: {'Confidence': 26.34, 'Fluency': 35.87}\n",
      "R² Score (Confidence, Fluency): [0.98137328 0.98478538]\n"
     ]
    }
   ],
   "source": [
    "# Example Prediction\n",
    "new_response = \"Um, I have experience in project management and, uh, data analysis.\"\n",
    "result = predict_response(new_response)\n",
    "print(f\"Predicted Scores: {result}\")\n",
    "print(f\"R² Score (Confidence, Fluency): {r2}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c87d853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/bert_interview_scorer\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/bert_interview_scorer\\assets\n"
     ]
    }
   ],
   "source": [
    "# Save the trained model in TensorFlow format\n",
    "model.save(\"saved_model/bert_interview_scorer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "07ee79b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['saved_model/scaler.pkl']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the scaler\n",
    "joblib.dump(scaler, \"saved_model/scaler.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a31785d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('saved_model/tokenizer\\\\tokenizer_config.json',\n",
       " 'saved_model/tokenizer\\\\special_tokens_map.json',\n",
       " 'saved_model/tokenizer\\\\vocab.txt',\n",
       " 'saved_model/tokenizer\\\\added_tokens.json')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the tokenizer\n",
    "tokenizer.save_pretrained(\"saved_model/tokenizer\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ef5a198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Shorya\\anaconda3\\lib\\site-packages\\keras\\src\\saving\\legacy\\saved_model\\load.py:107: The name tf.gfile.Exists is deprecated. Please use tf.io.gfile.exists instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Shorya\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\functional.py:156: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from transformers import BertTokenizer, TFBertModel\n",
    "import joblib\n",
    "\n",
    "# Load the model with custom_objects\n",
    "model = load_model(\"saved_model/bert_interview_scorer\", custom_objects={\"TFBertModel\": TFBertModel})\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Load the scaler\n",
    "scaler = joblib.load(\"saved_model/scaler.pkl\")\n",
    "\n",
    "# Define the function again\n",
    "def predict_response(response):\n",
    "    encoded = tokenizer(\n",
    "        [response],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=128,\n",
    "        return_tensors=\"tf\"\n",
    "    )\n",
    "    \n",
    "    prediction = model.predict({\n",
    "        'input_ids': encoded['input_ids'],\n",
    "        'attention_mask': encoded['attention_mask']\n",
    "    })\n",
    "    \n",
    "    prediction_rescaled = scaler.inverse_transform(prediction)[0]\n",
    "    confidence, fluency = prediction_rescaled\n",
    "    return {\"Confidence\": round(confidence, 2), \"Fluency\": round(fluency, 2)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cedef597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 135ms/step\n",
      "{'Confidence': 26.34, 'Fluency': 35.87}\n"
     ]
    }
   ],
   "source": [
    "# Test the loaded model\n",
    "response_text = \"Um, I have experience in project management and, uh, data analysis.\"\n",
    "result = predict_response(response_text)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59bfe41e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\shorya\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\shorya\\anaconda3\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: keras 3.9.0\n",
      "Uninstalling keras-3.9.0:\n",
      "  Successfully uninstalled keras-3.9.0\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall -y keras\n",
    "# !pip install keras==2.15.0\n",
    "# !pip install tf-keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c56efba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: tensorflow-intel 2.15.0\n",
      "Uninstalling tensorflow-intel-2.15.0:\n",
      "  Successfully uninstalled tensorflow-intel-2.15.0\n",
      "Found existing installation: tensorflow-estimator 2.15.0\n",
      "Uninstalling tensorflow-estimator-2.15.0:\n",
      "  Successfully uninstalled tensorflow-estimator-2.15.0\n",
      "Found existing installation: tf-keras 2.19.0\n",
      "Uninstalling tf-keras-2.19.0:\n",
      "  Successfully uninstalled tf-keras-2.19.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\shorya\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\shorya\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Skipping tensorflow as it is not installed.\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\shorya\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\shorya\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\shorya\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Skipping keras as it is not installed.\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\shorya\\anaconda3\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: tensorflow-io-gcs-filesystem 0.31.0\n",
      "Uninstalling tensorflow-io-gcs-filesystem-0.31.0:\n",
      "  Successfully uninstalled tensorflow-io-gcs-filesystem-0.31.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\shorya\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\shorya\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Skipping tensorflow-io as it is not installed.\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\shorya\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall -y tensorflow tensorflow-intel tensorflow-estimator keras tf-keras\n",
    "!pip uninstall -y tensorflow-io tensorflow-io-gcs-filesystem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93124904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow==2.15.0\n",
      "  Using cached tensorflow-2.15.0-cp39-cp39-win_amd64.whl (2.1 kB)\n",
      "Collecting keras==2.15.0\n",
      "  Using cached keras-2.15.0-py3-none-any.whl (1.7 MB)\n",
      "Collecting tensorflow-intel==2.15.0\n",
      "  Using cached tensorflow_intel-2.15.0-cp39-cp39-win_amd64.whl (300.8 MB)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\shorya\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow==2.15.0) (0.2.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\shorya\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow==2.15.0) (1.6.3)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in c:\\users\\shorya\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow==2.15.0) (1.12.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\shorya\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow==2.15.0) (21.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\shorya\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow==2.15.0) (61.2.0)\n",
      "Requirement already satisfied: ml-dtypes~=0.2.0 in c:\\users\\shorya\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow==2.15.0) (0.2.0)\n",
      "Requirement already satisfied: tensorboard<2.16,>=2.15 in c:\\users\\shorya\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow==2.15.0) (2.15.2)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\shorya\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow==2.15.0) (1.16.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\shorya\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow==2.15.0) (3.12.1)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\shorya\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow==2.15.0) (2.5.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in c:\\users\\shorya\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow==2.15.0) (1.26.4)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\shorya\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow==2.15.0) (0.6.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\shorya\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow==2.15.0) (4.25.6)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\shorya\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow==2.15.0) (4.12.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\shorya\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow==2.15.0) (1.71.0)\n",
      "Collecting tensorflow-estimator<2.16,>=2.15.0\n",
      "  Using cached tensorflow_estimator-2.15.0-py2.py3-none-any.whl (441 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Using cached tensorflow_io_gcs_filesystem-0.31.0-cp39-cp39-win_amd64.whl (1.5 MB)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\shorya\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow==2.15.0) (18.1.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\shorya\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow==2.15.0) (2.1.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\shorya\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow==2.15.0) (3.4.0)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in c:\\users\\shorya\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow==2.15.0) (25.2.10)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\shorya\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.15.0->tensorflow==2.15.0) (0.37.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in c:\\users\\shorya\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow==2.15.0) (1.2.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\shorya\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow==2.15.0) (0.7.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\shorya\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow==2.15.0) (3.3.4)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\shorya\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow==2.15.0) (2.0.3)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\shorya\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\shorya\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\shorya\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\shorya\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\shorya\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\shorya\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\shorya\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\shorya\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\shorya\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\shorya\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\shorya\\anaconda3\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\shorya\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow==2.15.0) (2.27.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\shorya\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow==2.15.0) (2.38.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\shorya\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow==2.15.0) (4.7.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\shorya\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow==2.15.0) (4.2.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\shorya\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow==2.15.0) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\shorya\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow==2.15.0) (2.0.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\shorya\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow==2.15.0) (0.4.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\shorya\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow==2.15.0) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\shorya\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow==2.15.0) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\shorya\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow==2.15.0) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\shorya\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow==2.15.0) (2021.10.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\shorya\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow==2.15.0) (3.2.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\shorya\\anaconda3\\lib\\site-packages (from packaging->tensorflow-intel==2.15.0->tensorflow==2.15.0) (3.0.4)\n",
      "Installing collected packages: tensorflow-io-gcs-filesystem, tensorflow-estimator, keras, tensorflow-intel, tensorflow\n",
      "Successfully installed keras-2.15.0 tensorflow-2.15.0 tensorflow-estimator-2.15.0 tensorflow-intel-2.15.0 tensorflow-io-gcs-filesystem-0.31.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow==2.15.0 keras==2.15.0\n",
    "# # !pip install tf-keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad7d61a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras Version: 2.15.0\n",
      "TensorFlow Version: 2.15.0\n",
      "Transformers Version: 4.49.0\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "import transformers\n",
    "\n",
    "print(\"Keras Version:\", keras.__version__)\n",
    "print(\"TensorFlow Version:\", tf.__version__)\n",
    "print(\"Transformers Version:\", transformers.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "465afaf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_difficulty(accuracy, confidence, fluency, current_difficulty):\n",
    "    # Calculate weighted score\n",
    "    weighted_score = (accuracy * 0.5) + (confidence * 2) + (fluency * 2)\n",
    "\n",
    "    # Adaptive difficulty selection\n",
    "    if weighted_score >= 80 and current_difficulty < 2:\n",
    "        return current_difficulty + 1  # Move to harder question\n",
    "    elif weighted_score <= 50 and current_difficulty > 0:\n",
    "        return current_difficulty - 1  # Move to easier question\n",
    "    return current_difficulty  # Keep the same difficulty\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f6df37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
